{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulya77/TFF/blob/main/01_neural_network_regression_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b673cb82",
      "metadata": {
        "id": "b673cb82"
      },
      "source": [
        "# Intro to regression with neural network\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we'are going to simplify it: predicting a numerical variable based on some other combinaion of variables, even shorter... predicting a number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2a38c4de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a38c4de",
        "outputId": "b1cd19c3-554b-4845-e80b-66af251e420a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "#Import TEnsorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5167f8b",
      "metadata": {
        "id": "a5167f8b"
      },
      "source": [
        "###Creating data to fit and view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2398481a",
      "metadata": {
        "id": "2398481a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#create features\n",
        "x=np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "\n",
        "#Create labels\n",
        "y= np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a41962ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "a41962ac",
        "outputId": "4ed361a7-66e7-4366-90f9-a798549d8855"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#visualize it\n",
        "plt.scatter(x,y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b74f981f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b74f981f",
        "outputId": "567352a8-4ff4-4c46-b9ce-ed24ec09dbca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "y==x+10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9dfa11",
      "metadata": {
        "id": "af9dfa11"
      },
      "source": [
        "# INput and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d4b2b44b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4b2b44b",
        "outputId": "aefcfbd5-6f6c-49f5-a2b3-452f659edc22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Create a tesnor for our housing price prediction\n",
        "house_info=tf.constant([\"bedroom\",\"bathroom\",\"garage\"])\n",
        "house_price=tf.constant([939700])\n",
        "house_info, house_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4dd3f89c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dd3f89c",
        "outputId": "3dc1b0b0-9fe4-4b8a-af54-b78e53f20f0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x[0],y[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9ed63650",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ed63650",
        "outputId": "7509c471-5c4b-4064-fd52-a138ee33d2a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x[1], y[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "866071f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866071f0",
        "outputId": "7c1c6584-7560-45ab-f793-82c5a036d0ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "input_shape=x.shape\n",
        "output_shape=y.shape\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "327afe63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "327afe63",
        "outputId": "9ce959c1-bc86-445a-f260-0121fd52787b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_shape=x[0].shape\n",
        "output_shape=y[0].shape\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eabf4333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eabf4333",
        "outputId": "f3c77b5a-e3a2-4976-db71-57f243d2173e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x[0].ndim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d1b7adf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1b7adf6",
        "outputId": "22903aa8-e30b-4659-d384-80c148d0dedf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x[0], y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ca3bcc00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca3bcc00",
        "outputId": "b63ecdb5-845d-4dda-8609-2cff36b74955"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        " #Turn out numpy array to tensors with dtype float 32\n",
        "'''\n",
        "at 4:44:50\n",
        "running first neural network\n",
        "Epoch 1/5\n",
        "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
        "\n",
        "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
        "\n",
        "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.'''\n",
        "x=tf.cast(tf.constant(x),dtype=tf.float32)\n",
        "y=tf.cast(tf.constant(y),dtype=tf.float32)\n",
        "x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d2f8b4bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2f8b4bf",
        "outputId": "6f5d1969-6a37-4fd6-8c90-ecae54c8c110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input_shape=x[0].shape\n",
        "output_shape=y[0].shape\n",
        "input_shape, output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c4344eca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "c4344eca",
        "outputId": "214eac6a-f833-4cd8-b508-b21e23b4f1ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(x,y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b484336b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b484336b",
        "outputId": "3a428d82-48ac-48e8-b88c-4db6a6de1119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'##OPtional creating \\n\\nmodel=tf.keras.Sequential()\\nmodel.add(tf.keras.layers.Dense(1))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "'''##OPtional creating \n",
        "\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2445582",
      "metadata": {
        "id": "b2445582"
      },
      "source": [
        "# STEPS in modelling with tensorflow\n",
        "**1.Creating a model**-define the input and output layers,  as well as the hidden layers of a deep learning model.\n",
        "\n",
        "**2.Compiling a model**- define the loss function(the function which tells our model how wrong it is)and the optimizer(tells how to improve the patterns its learning) and evaluation matrics(what we can use to interpret the performance of our model).\n",
        "\n",
        "**3.fitting a model**-letting the model try to find patterns between x&y (features and labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0a6c55c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6c55c7",
        "outputId": "2cb30554-04c9-4acd-e669-362a51b97baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88be5871d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\"CODE BY AMULYA\"\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "#model.fit(x, y, epochs=5) # this will break with TensorFlow 2.7.0+\n",
        "model.fit(tf.expand_dims(x, axis=-1), y, epochs=5)\n",
        "#epochs= laps or opportunities to fit the model that many times\n",
        "\n",
        "#epochs=how many time the model will go throug all of the training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ba8ca596",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba8ca596",
        "outputId": "e5c94dc3-a699-470c-a52a-293dc371e3e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Check out x and y\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fba6cb26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fba6cb26",
        "outputId": "3ae14266-9001-4bb9-f728-852f8507eca3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#Try and make prediction using our model\n",
        "y_pred=model.predict([17.0]) \n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2bf5e74e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bf5e74e",
        "outputId": "b67fc4a3-5719-4a68-91ce-b8b6238d98f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y_pred+11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53033e59",
      "metadata": {
        "id": "53033e59"
      },
      "source": [
        "# WATCH VIDEO AT 4:50:20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7349ebde",
      "metadata": {
        "id": "7349ebde"
      },
      "source": [
        "## IMPROVING THE MODEL\n",
        "\n",
        "we can improve our model, by altering steps \n",
        "\n",
        "1.**Creating a model**-here we might add more layers, increase the number of hidden units(all called neurons) within each of the hidden layers, change the activation function.\n",
        "\n",
        "2.**Compiling a model**- here wr might change the optimizing function or perhaps the **learnning rate** of the optimizing function.\n",
        "\n",
        "3.**fitting a model**-here we might fit a model for more **epochs**(leave it training for longer) or on more data (give model more examples to learn from)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d6e80b8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e80b8d",
        "outputId": "d3b4345e-830c-4c20-ef8d-8eff76b960f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bcb89790>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#lets rebuild our model\n",
        "\n",
        "#1. Create the model\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2.compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#3.fit the model\n",
        "#model.fit(x,y,epochs=100)\n",
        "model.fit(tf.expand_dims(x, axis=-1), y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2ac80bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ac80bac",
        "outputId": "f1acb2ed-8cdc-4b4c-b8ba-89ad70dd7ce9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "794af8e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "794af8e1",
        "outputId": "6674a5f1-a71d-4e4d-c0e6-35b8b94beb89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#lets see model prediction has improved\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01cf63a8",
      "metadata": {
        "id": "01cf63a8"
      },
      "source": [
        "# WATCH VIDEO AT 5:03:36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9142f1ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9142f1ab",
        "outputId": "eb933861-55cf-4fe4-8b1f-5b22a46b84cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 12.3193 - mae: 12.3193\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 11.5062 - mae: 11.5062\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 10.6739 - mae: 10.6739\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.8419 - mae: 9.8419\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.9962 - mae: 8.9962\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.1347 - mae: 8.1347\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.4053 - mae: 7.4053\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.6763 - mae: 6.6763\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.9141 - mae: 5.9141\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.1125 - mae: 5.1125\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.2653 - mae: 4.2653\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8460 - mae: 3.8460\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.9257 - mae: 3.9257\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0900 - mae: 4.0900\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.4780 - mae: 4.4780\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.7607 - mae: 4.7607\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.9264 - mae: 4.9264\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.9893 - mae: 4.9893\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.9672 - mae: 4.9672\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.8677 - mae: 4.8677\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.7046 - mae: 4.7046\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4896 - mae: 4.4896\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2326 - mae: 4.2326\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.9418 - mae: 3.9418\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7886 - mae: 3.7886\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6632 - mae: 3.6632\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5392 - mae: 3.5392\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.5531 - mae: 3.5531\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6208 - mae: 3.6208\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6577 - mae: 3.6577\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.7506 - mae: 3.7506\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7093 - mae: 3.7093\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5338 - mae: 3.5338\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4270 - mae: 3.4270\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3004 - mae: 3.3004\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1545 - mae: 3.1545\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0648 - mae: 3.0648\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0459 - mae: 3.0459\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.0209 - mae: 3.0209\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.0347 - mae: 3.0347\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9867 - mae: 2.9867\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8887 - mae: 2.8887\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8175 - mae: 2.8175\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7250 - mae: 2.7250\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6172 - mae: 2.6172\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5069 - mae: 2.5069\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4002 - mae: 2.4002\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2894 - mae: 2.2894\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1712 - mae: 2.1712\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0403 - mae: 2.0403\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9989 - mae: 1.9989\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8725 - mae: 1.8725\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7026 - mae: 1.7026\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5747 - mae: 1.5747\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4753 - mae: 1.4753\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3545 - mae: 1.3545\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2392 - mae: 1.2392\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0315 - mae: 1.0315\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8339 - mae: 0.8339\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6625 - mae: 0.6625\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5088 - mae: 0.5088\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3310 - mae: 0.3310\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3306 - mae: 0.3306\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3330 - mae: 0.3330\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2128 - mae: 0.2128\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6744 - mae: 0.6744\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6279 - mae: 0.6279\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6085 - mae: 0.6085\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7257 - mae: 0.7257\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6237 - mae: 0.6237\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3928 - mae: 0.3928\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5721 - mae: 0.5721\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6972 - mae: 0.6972\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4927 - mae: 0.4927\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5584 - mae: 0.5584\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5706 - mae: 0.5706\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4548 - mae: 0.4548\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2732 - mae: 0.2732\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6350 - mae: 0.6350\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7159 - mae: 0.7159\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4848 - mae: 0.4848\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3396 - mae: 0.3396\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2129 - mae: 0.2129\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3691 - mae: 0.3691\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4716 - mae: 0.4716\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3323 - mae: 0.3323\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2552 - mae: 0.2552\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3310 - mae: 0.3310\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2381 - mae: 0.2381\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2594 - mae: 0.2594\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2367 - mae: 0.2367\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1750 - mae: 0.1750\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2303 - mae: 0.2303\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1337 - mae: 0.1337\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1930 - mae: 0.1930\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1098 - mae: 0.1098\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2055 - mae: 0.2055\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1987 - mae: 0.1987\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2264 - mae: 0.2264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88be414e10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#Let's make another improvement\n",
        "\n",
        "#1/.Create a model with extra hhidden layers with 100 hidden units\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "#3 fit the model\n",
        "#model.fit(x,y,epochs=100)\n",
        "model.fit(tf.expand_dims(x, axis=-1), y, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e6ca88cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ca88cf",
        "outputId": "05cb123a-09d4-4f08-b3fe-65016d6e05c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c87d99d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c87d99d1",
        "outputId": "9217df02-bb3d-4d31-e59a-17f34160012a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.159163]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#lets see model prediction has improved\n",
        "model.predict([17.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Common ways to improve a deep model :\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Adding layers\n",
        "\n",
        " Increase the number of hidden units\n",
        "\n",
        " Change the activation functions\n",
        "\n",
        " Change the optimization function\n",
        "\n",
        ". **Change the learning rate**\n",
        "\n",
        " Fitting on more data\n",
        "\n",
        " Fitting for longer\n",
        "               ( because you can alter each of\n",
        "               these , they're hyperparameters )"
      ],
      "metadata": {
        "id": "7a9533a5"
      },
      "id": "7a9533a5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUATING A MODEL**\n",
        "A typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "**Build a model -> evaluate it -> build (tweak) a model -> evaulate it -> build (tweak) a model -> evaluate it...**\n",
        "\n",
        "\n",
        "The tweaking comes from maybe not building a model from scratch but adjusting an existing one."
      ],
      "metadata": {
        "id": "e7JsyJe61Ejs"
      },
      "id": "e7JsyJe61Ejs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize, visualize, visualize**\n",
        "\n",
        "When it comes to evaluation, you'll want to remember the words: \"visualize, visualize, visualize.\"\n",
        "\n",
        "This is because you're probably better looking at something (doing) than you are thinking about something.\n",
        "\n",
        "It's a good idea to visualize:\n",
        "\n",
        "**The data** - what data are you working with? What does it look like?\n",
        "\n",
        "**The model itself** - what does the architecture look like? What are the different shapes?\n",
        "\n",
        "**The training of a model** - how does a model perform while it learns?\n",
        "\n",
        "***The predictions of a model *** - how do the predictions of a model line up against the ground truth (the original labels)?\n",
        "\n",
        "Let's start by visualizing the model.\n",
        "\n",
        "But first, we'll create a little bit of a bigger dataset and a new model we can use (it'll be the same as before, but the more practice the better)."
      ],
      "metadata": {
        "id": "vhzPQsm411VD"
      },
      "id": "vhzPQsm411VD"
    },
    {
      "cell_type": "code",
      "source": [
        "#make a bigger dataset\n",
        "X=tf.range(-100,100,4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT5Y_WjE_-jA",
        "outputId": "37f80787-fe87-4182-fc52-9ddd947a4d85"
      },
      "id": "tT5Y_WjE_-jA",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make labels for dataset\n",
        "y=X+10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb0U8d9UAkAZ",
        "outputId": "8bf1d76d-594d-4d66-cff9-9ae8614f7eef"
      },
      "id": "Hb0U8d9UAkAZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #visualize the data\n",
        " import matplotlib.pyplot as plt\n",
        " plt.scatter(X,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "OVAkMUXACCe-",
        "outputId": "62aedf89-7f27-4fd8-cf73-0fbed1c5610c"
      },
      "id": "OVAkMUXACCe-",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f88bd5c1d50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###THE 3 sets \n",
        "Split data into training/test set-\n",
        "\n",
        "One of the other most common and important steps in a machine learning project is creating a training and test set (and when required, a validation set).\n",
        "\n",
        "Each set serves a specific purpose:\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available (like the course materials you study during the semester).\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the total data available (like the practice exam you take before the final exam).\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, it's typically 10-15% of the total data available (like the final exam you take at the end of the semester).\n",
        "For now, we'll just use a training and test set, this means we'll have a dataset for our model to learn on as well as be evaluated on.\n",
        "\n",
        "We can create them by splitting our X and y arrays.\n",
        "\n",
        " Note: When dealing with real-world data, this step is typically done right at the start of a project (the test set should always be kept separate from all other data). We want our model to learn on training data and then evaluate it on test data to get an indication of how well it generalizes to unseen examples."
      ],
      "metadata": {
        "id": "W8mWmGEWCZtk"
      },
      "id": "W8mWmGEWCZtk"
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the length of how many samples we have\n",
        "\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBByRBANCv19",
        "outputId": "e8230ecc-a9e1-4c1b-9a21-f365e4590b12"
      },
      "id": "IBByRBANCv19",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train = X[:40] # first 40 examples (80% of data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 examples (20% of data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test),len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_1PNdkPD5fJ",
        "outputId": "486423a7-85d0-4434-c894-d56fe9f22c9e"
      },
      "id": "z_1PNdkPD5fJ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing the data\n",
        "Now we've got our training and test data, it's a good idea to visualize it.\n",
        "\n",
        "Let's plot it with some nice colours to differentiate what's what."
      ],
      "metadata": {
        "id": "tp8qt5D-EJb-"
      },
      "id": "tp8qt5D-EJb-"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c='b', label='Training data')\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c='g', label='Testing data')\n",
        "# Show the legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Z_M7dES_Ea-j",
        "outputId": "3ebbe943-502b-4412-d249-e1989e09dffa"
      },
      "id": "Z_M7dES_Ea-j",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful! Any time you can visualize your data, your model, your anything, it's a good idea.\n",
        "\n",
        "With this graph in mind, what we'll be trying to do is build a model which learns the pattern in the blue dots (X_train) to draw the green dots (X_test).\n",
        "\n",
        "Time to build a model. We'll make the exact same one from before (the one we trained for longer)."
      ],
      "metadata": {
        "id": "d5FXzaU6EpKX"
      },
      "id": "d5FXzaU6EpKX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (same as above)\n",
        "#model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)"
      ],
      "metadata": {
        "id": "17yj92EFFsLY"
      },
      "id": "17yj92EFFsLY",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing the model\n",
        "After you've built a model, you might want to take a look at it (especially if you haven't built many before).\n",
        "\n",
        "You can take a look at the layers and shapes of your model by calling summary() on it.\n",
        "\n",
        " Note: Visualizing a model is particularly helpful when you run into input and output shape mismatches."
      ],
      "metadata": {
        "id": "6-XPbQXXFuqA"
      },
      "id": "6-XPbQXXFuqA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Doesn't work (model not fit/built)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "slLT19f8FzwK",
        "outputId": "1579b496-84a3-4b1f-e848-cfbce19a0170"
      },
      "id": "slLT19f8FzwK",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7d09d31d4e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Doesn't work (model not fit/built)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2776\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0],y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bks9idktF412",
        "outputId": "41bc598e-62a4-4131-989b-bf59fd318ea2"
      },
      "id": "Bks9idktF412",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=[1],name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1,name=\"output_layer\") # define the input_shape to our model\n",
        "],name=\"model_1\")\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "#DENSE means fully connected neural network"
      ],
      "metadata": {
        "id": "FC8der86G7vn"
      },
      "id": "FC8der86G7vn",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNzHrcAbHGTo",
        "outputId": "32ab25ee-d42f-4a12-cb24-7035a8dd5e1e"
      },
      "id": "jNzHrcAbHGTo",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling summary() on our model shows us the layers it contains, the output shape and the number of parameters.\n",
        "\n",
        "* Total params - total number of parameters in the model.\n",
        "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
        "* Non-trainable parameters - these parameters aren't updated during training (this is typical when you bring in the already learned patterns from other models during **transfer learning**).\n",
        "\n",
        " *** Resource:***  For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video.\n",
        "\n",
        " Exercise: Try playing around with the number of hidden units in the Dense layer (e.g. Dense(2), Dense(3)). How does this change the Total/Trainable params? Investigate what's causing the change.\n",
        "\n",
        "For now, all you need to think about these parameters is that their learnable patterns in the data.\n",
        "\n",
        "Let's fit our model to the training data."
      ],
      "metadata": {
        "id": "tlGtAo1cHjpg"
      },
      "id": "tlGtAo1cHjpg"
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's fit our model to the training data\n",
        "model.fit(X_train,y_train,epochs=100,verbose=0)"
      ],
      "metadata": {
        "id": "_SX2nCdTH8RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe4a30d-7614-442e-8cdc-19fef1f14a60"
      },
      "id": "_SX2nCdTH8RZ",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88be2bd750>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a summary of model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCVwpFlFw7gV",
        "outputId": "8fe62f5f-0827-4680-b8e2-67b093147e3a"
      },
      "id": "dCVwpFlFw7gV",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model,show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "jp7Z-Xabw_Z2",
        "outputId": "7b89a561-cabb-4dc8-e410-10e1ca472be7"
      },
      "id": "jp7Z-Xabw_Z2",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing model predictions\n",
        "\n",
        "\n",
        "Now we've got a trained model, let's visualize some predictions.\n",
        "\n",
        "To visualize predictions, it's always a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of y_test vs. y_pred (ground truth vs. predictions).\n",
        "\n",
        "First, we'll make some predictions on the test data (X_test), remember the model has never seen the test data."
      ],
      "metadata": {
        "id": "H1DL81Y4xKYI"
      },
      "id": "H1DL81Y4xKYI"
    },
    {
      "cell_type": "code",
      "source": [
        "#make some predictions\n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIVE8PQI8cjj",
        "outputId": "1478f26c-a6be-47bd-c90f-73a9d31fc89d"
      },
      "id": "aIVE8PQI8cjj",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8NUtNkC9EGx",
        "outputId": "3432f1b4-2e7e-4838-8ca5-5314f9479a55"
      },
      "id": "O8NUtNkC9EGx",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " Note: If you think you're going to be visualizing something a lot, it's a good idea to functionize it so you can use it later."
      ],
      "metadata": {
        "id": "cAbkC_re9Il_"
      },
      "id": "cAbkC_re9Il_"
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a plotting function\n",
        "\n",
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot the predictions in red (predictions were made on the test data)\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "A9KqRm7l9VCM"
      },
      "id": "A9KqRm7l9VCM",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4oSTaFSr_CcX",
        "outputId": "a52c012a-5a49-4352-bbab-5aafeba4f7ad"
      },
      "id": "4oSTaFSr_CcX",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluating predictions\n",
        "Alongisde visualizations, evaulation metrics are your alternative best option for evaluating your model.\n",
        "\n",
        "Depending on the problem you're working on, different models have different evaluation metrics.\n",
        "\n",
        "Two of the main metrics used for regression problems are:\n",
        "\n",
        "* Mean absolute error (MAE) - the mean difference between each of the predictions.\n",
        "* Mean squared error (MSE) - the squared mean difference between of the predictions (use if larger errors are more detrimental than smaller errors).\n",
        "The lower each of these values, the better.\n",
        "\n",
        "You can also use model.evaluate() which will return the loss of the model as well as any metrics setup during the compile step."
      ],
      "metadata": {
        "id": "F_inkj6ZAQ4q"
      },
      "id": "F_inkj6ZAQ4q"
    },
    {
      "cell_type": "code",
      "source": [
        " #Evaluate the model on test\n",
        " model.evaluate(X_test,y_test)\n"
      ],
      "metadata": {
        "id": "yttuz7jABPwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ed1d91-bf9a-4a38-e30c-2dda6555df1e"
      },
      "id": "yttuz7jABPwH",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 177ms/step - loss: 3.1969 - mae: 3.1969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196942090988159, 3.196942090988159]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.constant(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTtVlkDgIyiv",
        "outputId": "2896a1a7-0c8f-4e09-a947-9cca4112e940"
      },
      "id": "xTtVlkDgIyiv",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppIzb4KIJiQ_",
        "outputId": "59fb24fe-3ddc-456d-ef4d-4dcbf486390a"
      },
      "id": "ppIzb4KIJiQ_",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the  MAE\n",
        "mae=tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                   y_pred=tf.constant(y_pred))\n",
        "mae\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eAdzgmFJjuP",
        "outputId": "f8f8e1f5-164c-4e8a-a078-0651ba09ffb2"
      },
      "id": "3eAdzgmFJjuP",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR34gC-tKMpn",
        "outputId": "f18db728-5f89-410c-aeff-d8c8bdc0a1bc"
      },
      "id": "IR34gC-tKMpn",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
              "        93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the  MAE\n",
        "mae=tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                   y_pred=tf.squeeze(y_pred))\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHHjcytiK0ne",
        "outputId": "ac8db768-2870-4ffe-d227-7b87397219c7"
      },
      "id": "HHHjcytiK0ne",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the MSE\n",
        "mse=tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                   y_pred=tf.squeeze(y_pred))\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw3f8zB-K3jt",
        "outputId": "9d6784de-4320-4e82-fc6c-6fbf95656e82"
      },
      "id": "Jw3f8zB-K3jt",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAke some fuunction to reuse mae and mse\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                        y_pred=tf.squeeze(y_pred))\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                        y_pred=tf.squeeze(y_pred))  "
      ],
      "metadata": {
        "id": "kJN9XktxLh5l"
      },
      "id": "kJN9XktxLh5l",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RUNNING experiments to rebuild our model\n",
        "\n",
        "```\n",
        "Build a model - > fit it - > evaluate it - > tweak it - > fit it - > evaluate it - > tweak it - > fit it - > evaluate it ...\n",
        "```\n",
        "  1. Get more data - get more examples for your model to train on ( more opportunities to learn patterns or relationships between features and\n",
        "    labels ) .\n",
        " 2. Make your model larger ( using a more complex model ) - this might come in the form of more layers or more hidden units in each layer .\n",
        " 3. Train for longer - give your model more of a chance to find patterns in the data ."
      ],
      "metadata": {
        "id": "hOGyyf-5ML_n"
      },
      "id": "hOGyyf-5ML_n"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vJMvaCsNEWx",
        "outputId": "60c06bc1-1f19-4bc6-f05d-602d6158a85d"
      },
      "id": "8vJMvaCsNEWx",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56], dtype=int32)>,\n",
              " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running experiments to improve a model\n",
        "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
        "\n",
        "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
        "\n",
        "Get more data - get more examples for your model to train on (more opportunities to learn patterns).\n",
        "Make your model larger (use a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
        "Train for longer - give your model more of a chance to find the patterns in the data.\n",
        "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
        "\n",
        "So let's take a look at how we can improve our model using 2 and 3.\n",
        "\n",
        "To do so, we'll build 3 models and compare their results:\n",
        "\n",
        "`model_1` - same as original model, 1 layer, trained for 100 epochs.\n",
        "\n",
        "`model_2` - 2 layers, trained for 100 epochs.\n",
        "\n",
        "`model_3` - 2 layers, trained for 500 epochs.\n",
        "\n",
        "**Build `model_1`**\n",
        "\n"
      ],
      "metadata": {
        "id": "NSn9bTykNc6p"
      },
      "id": "NSn9bTykNc6p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t51UatX7N-uN",
        "outputId": "a19a83d7-e1c2-4e79-86e8-77095ffc73cd"
      },
      "id": "t51UatX7N-uN",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88be09ce90>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a plot prediction for model1\n",
        "\n",
        "y_preds_1=model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "-ggPf38zPho7",
        "outputId": "ce8546b9-259f-4300-8184-924577c17ddc"
      },
      "id": "-ggPf38zPho7",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88bdfb3d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model_1 evauation metrics\n",
        "mae_1=mae(y_test,y_preds_1)\n",
        "mse_1=mse(y_test,y_preds_1)\n",
        "mae_1,mse_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbtOCRj1OM87",
        "outputId": "046bdcf6-2ead-46fd-accb-8cef08996770"
      },
      "id": "dbtOCRj1OM87",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build model 2 for \n",
        "* 2 dense layer for 100 epochs"
      ],
      "metadata": {
        "id": "Rfs78yW0QYR5"
      },
      "id": "Rfs78yW0QYR5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mse'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLg787B5Q-69",
        "outputId": "30636269-33ff-404e-daa7-0d398cb38867"
      },
      "id": "zLg787B5Q-69",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.6625 - mse: 730.7203\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.9439 - mse: 457.8568\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.8059 - mse: 246.0893\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.4504 - mse: 427.5064\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0637 - mse: 183.7775\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.8335 - mse: 113.4307\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7023 - mse: 138.7539\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8713 - mse: 139.0908\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.0435 - mse: 2242.6597\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.6226 - mse: 922.2128\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.2375 - mse: 148.0953\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.1960 - mse: 884.4738\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0177 - mse: 401.7120\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.9747 - mse: 1054.3958\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.0365 - mse: 452.3428\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.3513 - mse: 80.3572\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.8516 - mse: 174.5898\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5119 - mse: 564.6961\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3378 - mse: 167.9056\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.6840 - mse: 454.6942\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.8826 - mse: 346.4473\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.1778 - mse: 284.4783\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.7814 - mse: 91.6130\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0673 - mse: 153.6725\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6998 - mse: 234.4242\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.2395 - mse: 1029.1600\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7524 - mse: 195.8459\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.9252 - mse: 839.5217\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.2439 - mse: 96.5096\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.3121 - mse: 1541.4504\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 53.1141 - mse: 5048.5190\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3708 - mse: 223.5310\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.1831 - mse: 182.1444\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.9483 - mse: 869.1888\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.6223 - mse: 243.1389\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5243 - mse: 660.7560\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.3913 - mse: 150.3677\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.4744 - mse: 269.5719\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.7992 - mse: 139.4418\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.6026 - mse: 399.9462\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9797 - mse: 180.0730\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3049 - mse: 115.2751\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5985 - mse: 111.1603\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.9750 - mse: 1255.0880\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2865 - mse: 146.9482\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.0574 - mse: 288.2434\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.5113 - mse: 256.8898\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.3531 - mse: 408.5314\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5141 - mse: 98.5780\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.6965 - mse: 252.8125\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5602 - mse: 152.9113\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.1688 - mse: 1569.2102\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7142 - mse: 277.9872\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.3987 - mse: 1068.3807\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9838 - mse: 1024.2789\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.2307 - mse: 171.5243\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.2025 - mse: 217.5930\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.8624 - mse: 107.3248\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3870 - mse: 253.6116\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9240 - mse: 141.0092\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.5375 - mse: 244.9044\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.6004 - mse: 472.9572\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1937 - mse: 88.0222\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.4644 - mse: 495.5126\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1481 - mse: 115.8306\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.3358 - mse: 894.4567\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9262 - mse: 144.0203\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8005 - mse: 160.7119\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.3093 - mse: 785.6154\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8134 - mse: 143.8698\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9715 - mse: 347.1664\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1469 - mse: 109.9948\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4683 - mse: 153.5231\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.1492 - mse: 1109.9485\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2183 - mse: 145.7852\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1686 - mse: 219.4318\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.4013 - mse: 531.0851\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0304 - mse: 91.7328\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.4407 - mse: 821.9720\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.1121 - mse: 1047.6493\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4009 - mse: 158.5122\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.5022 - mse: 227.8562\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1948 - mse: 384.5736\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6097 - mse: 64.8605\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2735 - mse: 574.6544\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1761 - mse: 115.6941\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.3047 - mse: 826.4014\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.9693 - mse: 511.1575\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1749 - mse: 70.5006\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.2784 - mse: 496.0709\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3343 - mse: 256.6013\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7404 - mse: 127.3696\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1947 - mse: 276.4909\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.1954 - mse: 437.7806\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.7777 - mse: 385.2820\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1365 - mse: 209.8283\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.1982 - mse: 641.4230\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4874 - mse: 139.7856\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5632 - mse: 294.5455\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7188 - mse: 465.6695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bdfa2290>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "H-dPoILpRZb9",
        "outputId": "a007362a-ce5c-4b48-d6ec-56d286a8d578"
      },
      "id": "H-dPoILpRZb9",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88bded6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model_2 evauation metrics\n",
        "mae_2=mae(y_test,y_preds_2)\n",
        "mse_2=mse(y_test,y_preds_2)\n",
        "mae_2,mse_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqEysoa1RMXu",
        "outputId": "0361d1d5-8e5a-418a-80a8-a52bf0528baf"
      },
      "id": "jqEysoa1RMXu",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=1.9098114>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=5.459232>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BUILD MODEL 3***"
      ],
      "metadata": {
        "id": "iSfvwFRMRTPD"
      },
      "id": "iSfvwFRMRTPD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mse'])\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYZ55vTbSWSS",
        "outputId": "22674cee-7e7d-45e1-b202-324e9f8e0db0"
      },
      "id": "lYZ55vTbSWSS",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.6625 - mse: 730.7203\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.9439 - mse: 457.8568\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8059 - mse: 246.0893\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4504 - mse: 427.5064\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0637 - mse: 183.7775\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8335 - mse: 113.4307\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7023 - mse: 138.7539\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8713 - mse: 139.0908\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 38.0435 - mse: 2242.6597\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.6226 - mse: 922.2128\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.2375 - mse: 148.0953\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.1960 - mse: 884.4738\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0177 - mse: 401.7120\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9747 - mse: 1054.3958\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.0365 - mse: 452.3428\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3513 - mse: 80.3572\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8516 - mse: 174.5898\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.5119 - mse: 564.6961\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3378 - mse: 167.9056\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.6840 - mse: 454.6942\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.8826 - mse: 346.4473\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.1778 - mse: 284.4783\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7814 - mse: 91.6130\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0673 - mse: 153.6725\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6998 - mse: 234.4242\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.2395 - mse: 1029.1600\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7524 - mse: 195.8459\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.9252 - mse: 839.5217\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2439 - mse: 96.5096\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.3121 - mse: 1541.4504\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 53.1141 - mse: 5048.5190\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3708 - mse: 223.5310\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.1831 - mse: 182.1444\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.9483 - mse: 869.1888\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6223 - mse: 243.1389\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.5243 - mse: 660.7560\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.3913 - mse: 150.3677\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.4744 - mse: 269.5719\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7992 - mse: 139.4418\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6026 - mse: 399.9462\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.9797 - mse: 180.0730\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3049 - mse: 115.2751\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5985 - mse: 111.1603\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.9750 - mse: 1255.0880\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2865 - mse: 146.9482\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0574 - mse: 288.2434\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.5113 - mse: 256.8898\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.3531 - mse: 408.5314\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5141 - mse: 98.5780\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6965 - mse: 252.8125\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5602 - mse: 152.9113\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.1688 - mse: 1569.2102\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7142 - mse: 277.9872\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.3987 - mse: 1068.3807\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9838 - mse: 1024.2789\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2307 - mse: 171.5243\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2025 - mse: 217.5930\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.8624 - mse: 107.3248\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3870 - mse: 253.6116\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9240 - mse: 141.0092\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.5375 - mse: 244.9044\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6004 - mse: 472.9572\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.1937 - mse: 88.0222\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.4644 - mse: 495.5126\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1481 - mse: 115.8306\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.3358 - mse: 894.4567\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9262 - mse: 144.0203\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8005 - mse: 160.7119\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.3093 - mse: 785.6154\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8134 - mse: 143.8698\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9715 - mse: 347.1664\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1469 - mse: 109.9948\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4683 - mse: 153.5231\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.1492 - mse: 1109.9485\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2183 - mse: 145.7852\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.1686 - mse: 219.4318\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.4013 - mse: 531.0851\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0304 - mse: 91.7328\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.4407 - mse: 821.9720\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.1121 - mse: 1047.6493\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4009 - mse: 158.5122\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.5022 - mse: 227.8562\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1948 - mse: 384.5736\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6097 - mse: 64.8605\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2735 - mse: 574.6544\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1761 - mse: 115.6941\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.3047 - mse: 826.4014\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.9693 - mse: 511.1575\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1749 - mse: 70.5006\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.2784 - mse: 496.0709\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3343 - mse: 256.6013\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7404 - mse: 127.3696\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1947 - mse: 276.4909\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.1954 - mse: 437.7806\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.7777 - mse: 385.2820\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.1365 - mse: 209.8283\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.1982 - mse: 641.4230\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.4874 - mse: 139.7856\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.5632 - mse: 294.5455\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7188 - mse: 465.6695\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2612 - mse: 165.8038\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.9771 - mse: 402.6254\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7652 - mse: 81.8913\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.3546 - mse: 686.0342\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.1003 - mse: 621.3286\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1066 - mse: 173.2289\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.8571 - mse: 901.6235\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.7660 - mse: 326.4625\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.9636 - mse: 104.8116\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2212 - mse: 134.2834\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.8236 - mse: 218.5500\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.6233 - mse: 383.1098\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1865 - mse: 174.8858\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.8269 - mse: 965.1994\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.4715 - mse: 254.1559\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3496 - mse: 293.7750\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9493 - mse: 127.3319\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0617 - mse: 151.0345\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1352 - mse: 86.1702\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.7021 - mse: 1415.1868\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1569 - mse: 73.8880\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.1132 - mse: 1318.8975\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.8910 - mse: 1699.3580\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.3869 - mse: 618.4075\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0836 - mse: 158.3776\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2367 - mse: 113.9579\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2743 - mse: 195.7188\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.0387 - mse: 416.3107\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9837 - mse: 115.6224\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.7027 - mse: 791.5422\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7015 - mse: 127.5695\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9953 - mse: 483.5797\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7527 - mse: 61.9668\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.1873 - mse: 601.6000\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.5004 - mse: 148.9105\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.1094 - mse: 463.7339\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.9300 - mse: 708.8666\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0650 - mse: 140.6989\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8799 - mse: 147.0239\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.2794 - mse: 380.7041\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4378 - mse: 89.2005\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 36.5281 - mse: 2345.0383\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.2531 - mse: 901.5988\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4689 - mse: 184.6169\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.8080 - mse: 901.0599\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9834 - mse: 131.9920\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.7007 - mse: 290.2057\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.8050 - mse: 437.3918\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4769 - mse: 105.6434\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6249 - mse: 66.2061\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.9286 - mse: 520.4105\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4785 - mse: 137.2661\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 30.5114 - mse: 1352.1899\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9628 - mse: 178.4945\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.7147 - mse: 365.9752\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.5991 - mse: 461.2215\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.2962 - mse: 1574.9830\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2597 - mse: 139.8443\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7076 - mse: 97.8372\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.8764 - mse: 627.7489\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.8638 - mse: 208.3312\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.8614 - mse: 689.6600\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.5262 - mse: 549.2026\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4217 - mse: 196.5360\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6115 - mse: 227.3884\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.3573 - mse: 670.1419\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.8833 - mse: 1100.4496\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0079 - mse: 120.8836\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.1243 - mse: 828.4338\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5960 - mse: 170.5477\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.8613 - mse: 378.2540\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.8936 - mse: 285.0437\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.5890 - mse: 721.6298\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.3498 - mse: 179.6900\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.0652 - mse: 651.0244\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4087 - mse: 68.9827\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5979 - mse: 105.2246\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4691 - mse: 344.7029\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3098 - mse: 120.5476\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.1326 - mse: 94.0285\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.6995 - mse: 503.9971\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7752 - mse: 151.4990\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 10.9010 - mse: 174.2538\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.6795 - mse: 1722.8424\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6256 - mse: 93.5220\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.7550 - mse: 399.0123\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.1933 - mse: 192.4799\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.0484 - mse: 778.8578\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8744 - mse: 134.0267\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.2768 - mse: 328.6223\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9642 - mse: 171.7544\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9958 - mse: 293.6818\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.6780 - mse: 1218.4763\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.3824 - mse: 126.6317\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.9099 - mse: 247.8456\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9535 - mse: 825.6362\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.7607 - mse: 413.4920\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.4553 - mse: 197.8651\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.5603 - mse: 549.8512\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.7255 - mse: 371.4342\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5874 - mse: 226.1746\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.4504 - mse: 699.8113\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.6605 - mse: 665.3832\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.2725 - mse: 450.9420\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4795 - mse: 127.8898\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1134 - mse: 169.0442\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.6008 - mse: 468.0797\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3340 - mse: 296.6076\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.6363 - mse: 409.7261\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 18.1361 - mse: 479.5226\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9325 - mse: 146.0996\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.5932 - mse: 521.4794\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.9830 - mse: 305.9312\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.5550 - mse: 291.6794\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.2258 - mse: 794.7158\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.5046 - mse: 282.9926\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9874 - mse: 140.5887\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4790 - mse: 204.9319\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3193 - mse: 41.0249\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4031 - mse: 243.2198\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.3804 - mse: 729.0441\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.4821 - mse: 721.1590\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.6657 - mse: 197.6638\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.5729 - mse: 261.8083\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.7083 - mse: 320.0955\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9526 - mse: 317.8378\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.2855 - mse: 324.9458\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4495 - mse: 457.8130\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2128 - mse: 93.3408\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4579 - mse: 69.0919\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.7665 - mse: 906.1374\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.7807 - mse: 97.0748\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.7248 - mse: 888.0256\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1448 - mse: 94.6025\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7116 - mse: 232.8114\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7151 - mse: 76.4931\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0243 - mse: 134.4084\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5508 - mse: 93.3234\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.8639 - mse: 531.2301\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9871 - mse: 108.9976\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.3864 - mse: 278.7953\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8832 - mse: 107.2179\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.2384 - mse: 565.2567\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.9083 - mse: 272.0236\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5554 - mse: 283.9777\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6931 - mse: 362.9696\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.5340 - mse: 412.9678\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0999 - mse: 250.0800\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.4328 - mse: 284.7298\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 27.8382 - mse: 1102.6047\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.5069 - mse: 69.6516\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 38.1139 - mse: 2399.1333\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.9281 - mse: 739.2133\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4438 - mse: 73.3204\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.8148 - mse: 974.7941\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.7325 - mse: 275.6218\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.3459 - mse: 111.0881\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.2279 - mse: 273.9163\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.2463 - mse: 150.8060\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.6563 - mse: 1746.1848\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4289 - mse: 223.9082\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.9121 - mse: 124.0240\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.2714 - mse: 98.8414\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.8088 - mse: 493.9628\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7215 - mse: 201.3457\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.5943 - mse: 261.9935\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2338 - mse: 225.5727\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.5453 - mse: 567.3043\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 39.5157 - mse: 2410.1794\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1134 - mse: 226.2820\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3649 - mse: 280.9399\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.7528 - mse: 1059.1031\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2436 - mse: 90.5191\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.4461 - mse: 48.8843\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.9599 - mse: 1854.4125\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0558 - mse: 117.6499\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.1170 - mse: 924.9803\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3321 - mse: 225.7084\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1102 - mse: 390.2373\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.2435 - mse: 681.9950\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.7810 - mse: 864.0096\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2441 - mse: 96.3634\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4285 - mse: 98.4292\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.6308 - mse: 1076.0869\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.2314 - mse: 321.7988\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2458 - mse: 36.7862\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.8119 - mse: 649.3243\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.6881 - mse: 1164.0315\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0046 - mse: 240.5404\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.1976 - mse: 347.7951\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3652 - mse: 392.0552\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.6295 - mse: 284.5078\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9419 - mse: 365.1537\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.0848 - mse: 863.7568\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.7127 - mse: 314.7092\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5065 - mse: 28.6100\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6685 - mse: 206.4920\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.7733 - mse: 823.7953\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.0267 - mse: 540.4344\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.8169 - mse: 118.8355\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.8882 - mse: 364.8494\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.7412 - mse: 53.5266\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.9852 - mse: 781.2346\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.0575 - mse: 936.0121\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5871 - mse: 145.9317\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.8152 - mse: 444.7377\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7940 - mse: 179.0320\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.5450 - mse: 648.9275\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6686 - mse: 291.5800\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6468 - mse: 97.3312\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3861 - mse: 251.1910\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 30.1870 - mse: 1258.0659\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2613 - mse: 104.6679\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5500 - mse: 261.4684\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.5548 - mse: 807.1274\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.4469 - mse: 326.8018\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.0025 - mse: 549.0877\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.0088 - mse: 83.5278\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.1318 - mse: 487.3890\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.6560 - mse: 193.8438\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0358 - mse: 108.2257\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6712 - mse: 170.5333\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3342 - mse: 519.9540\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.3114 - mse: 53.0342\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.6204 - mse: 319.9394\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9930 - mse: 75.6124\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.6297 - mse: 446.7985\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.3738 - mse: 290.6261\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6862 - mse: 479.6744\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7832 - mse: 92.5273\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 19.7392 - mse: 592.2516\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5504 - mse: 172.7362\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3365 - mse: 395.8149\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7204 - mse: 198.8242\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.0571 - mse: 267.4103\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.4954 - mse: 1440.2836\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0398 - mse: 189.8356\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.9557 - mse: 586.2054\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 34.3118 - mse: 1762.2278\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7204 - mse: 107.9195\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.9521 - mse: 673.2414\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.8474 - mse: 256.6476\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.6931 - mse: 181.4209\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6911 - mse: 227.7046\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.9080 - mse: 1343.6309\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6418 - mse: 260.5357\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.5682 - mse: 915.7301\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.2760 - mse: 273.2400\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.0389 - mse: 249.4207\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.4016 - mse: 327.4286\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 32.8786 - mse: 1517.4860\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.0887 - mse: 279.8365\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7845 - mse: 485.2440\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3456 - mse: 232.8857\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.7768 - mse: 1024.7793\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1413 - mse: 177.8806\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.6965 - mse: 339.9479\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.5669 - mse: 322.9643\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3553 - mse: 311.8373\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3741 - mse: 623.6090\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8611 - mse: 217.9780\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8143 - mse: 78.2297\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.7580 - mse: 819.9232\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.4392 - mse: 1256.8704\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2609 - mse: 106.5675\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1080 - mse: 49.6609\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.5084 - mse: 1805.7731\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3386 - mse: 101.1376\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6853 - mse: 109.2358\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.2204 - mse: 317.2863\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8365 - mse: 85.1076\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5532 - mse: 77.9333\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.1444 - mse: 863.4313\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2379 - mse: 209.3896\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.8609 - mse: 234.7540\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.7345 - mse: 316.5263\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6624 - mse: 296.2131\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.1848 - mse: 410.1581\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.6248 - mse: 586.8312\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 34.1467 - mse: 1752.2295\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8398 - mse: 122.8955\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5903 - mse: 163.2769\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7475 - mse: 50.2140\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7343 - mse: 125.3748\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9610 - mse: 41.3965\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.1394 - mse: 907.0111\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.0848 - mse: 355.4001\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6537 - mse: 100.6408\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.5735 - mse: 460.8153\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.8722 - mse: 850.6849\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4860 - mse: 411.7528\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3799 - mse: 172.3636\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.1540 - mse: 513.4056\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.2061 - mse: 278.2711\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.6830 - mse: 1141.1149\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2067 - mse: 109.3232\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4882 - mse: 204.9571\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.3829 - mse: 81.4053\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.5525 - mse: 367.1143\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.7261 - mse: 61.1380\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9880 - mse: 114.5260\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3915 - mse: 388.5346\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3790 - mse: 294.2719\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.9715 - mse: 740.5031\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.0145 - mse: 497.2540\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0428 - mse: 75.7452\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.5847 - mse: 268.6655\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.6744 - mse: 41.2307\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.0699 - mse: 1494.7994\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2949 - mse: 219.1242\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9031 - mse: 287.3436\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.8005 - mse: 726.2508\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5131 - mse: 244.6434\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.0941 - mse: 87.2198\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.2518 - mse: 240.5244\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.4880 - mse: 1042.7231\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4894 - mse: 204.0924\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8735 - mse: 237.8829\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9124 - mse: 377.5442\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.8210 - mse: 854.1061\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2069 - mse: 436.7217\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8224 - mse: 154.4592\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.4446 - mse: 912.0034\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9594 - mse: 364.6487\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1071 - mse: 74.7382\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.1569 - mse: 562.3419\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2677 - mse: 85.5553\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6563 - mse: 271.2980\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0960 - mse: 230.8610\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0939 - mse: 243.1200\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0177 - mse: 194.1771\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3634 - mse: 291.0750\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 11.3840 - mse: 294.8225\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.4181 - mse: 1298.2200\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5025 - mse: 281.7765\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.9030 - mse: 1217.9524\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6079 - mse: 208.5047\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7370 - mse: 263.3251\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 33.6905 - mse: 1571.6898\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1092 - mse: 295.3281\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4910 - mse: 488.4590\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.3351 - mse: 752.7374\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.5134 - mse: 779.1820\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9375 - mse: 202.1430\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.9323 - mse: 317.4008\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 18.0209 - mse: 516.8447\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.4084 - mse: 51.2657\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0721 - mse: 252.4825\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.0213 - mse: 277.7128\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.7930 - mse: 425.7096\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.2969 - mse: 304.1502\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.6382 - mse: 1331.4302\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6471 - mse: 157.7731\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.1639 - mse: 1106.1194\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9552 - mse: 118.6147\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.4065 - mse: 288.3132\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.0418 - mse: 319.1999\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5709 - mse: 441.0256\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.8802 - mse: 1035.2952\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.4289 - mse: 249.5809\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4970 - mse: 272.4908\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3265 - mse: 245.4906\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.5723 - mse: 1221.5261\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.4551 - mse: 21.8035\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.2294 - mse: 354.1498\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 20.8631 - mse: 652.7772\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 30.4324 - mse: 1412.7607\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0177 - mse: 235.8264\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.7861 - mse: 276.9731\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2208 - mse: 14.0082\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.7157 - mse: 374.0391\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4055 - mse: 253.6523\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2931 - mse: 397.8472\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7605 - mse: 304.2992\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4321 - mse: 398.5485\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.0069 - mse: 277.6955\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.5862 - mse: 1302.6930\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.1694 - mse: 172.4573\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.2276 - mse: 271.3867\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8935 - mse: 483.7580\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.8000 - mse: 367.5784\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.2924 - mse: 697.5914\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.4153 - mse: 957.7278\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.0084 - mse: 813.2847\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.7663 - mse: 53.7044\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.0279 - mse: 566.8309\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.0383 - mse: 285.9872\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.6057 - mse: 1334.4749\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.9324 - mse: 237.5113\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7299 - mse: 252.6417\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.6069 - mse: 837.4230\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.5582 - mse: 593.3915\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.9865 - mse: 47.9242\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8093 - mse: 248.1184\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.3707 - mse: 238.8326\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6678 - mse: 241.5605\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6088 - mse: 515.0215\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5821 - mse: 817.9384\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3903 - mse: 136.4270\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.6258 - mse: 294.9864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bdf5bd10>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_3\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "S5I2G4g-Sdef",
        "outputId": "6f6646bc-b2b7-4125-bea6-07efcd1ea199"
      },
      "id": "S5I2G4g-Sdef",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model_3 evauation metrics\n",
        "mae_3=mae(y_test,y_preds_3)\n",
        "mse_3=mse(y_test,y_preds_3)\n",
        "mae_3,mse_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K70lIHRSmvP",
        "outputId": "de068ea6-76fe-49c1-9461-1b6c6a1711e0"
      },
      "id": "2K70lIHRSmvP",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.68786>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4804.4717>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing results**\n",
        "\n",
        "Now we've got results for 3 similar but slightly different results, let's compare them."
      ],
      "metadata": {
        "id": "HiuS4wPwSz_I"
      },
      "id": "HiuS4wPwSz_I"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcXfB_3-TNmK"
      },
      "id": "HcXfB_3-TNmK",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy\n",
        "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
        "all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5-PR3kcrTYps",
        "outputId": "358c18ef-c7f1-4051-e25c-86dc54f6521b"
      },
      "id": "5-PR3kcrTYps",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   1.909811     5.459232\n",
              "2  model_3  68.687859  4804.471680"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32bb2ade-e405-45a5-a0ab-cd2c0bb1551a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>1.909811</td>\n",
              "      <td>5.459232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.687859</td>\n",
              "      <td>4804.471680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32bb2ade-e405-45a5-a0ab-cd2c0bb1551a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32bb2ade-e405-45a5-a0ab-cd2c0bb1551a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32bb2ade-e405-45a5-a0ab-cd2c0bb1551a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`looks like model 2 performs well`\n"
      ],
      "metadata": {
        "id": "WuyGbP4jUdC9"
      },
      "id": "WuyGbP4jUdC9"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFnMGwJeTaGE",
        "outputId": "567a8a93-24af-45ee-c35e-ad4e9d6763aa"
      },
      "id": "cFnMGwJeTaGE",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our experiments, it looks like model_2 performed the best.\n",
        "\n",
        "And now, you might be thinking, \"wow, comparing models is tedious...\" and it definitely can be, we've only compared 3 models here.\n",
        "\n",
        "But this is part of what machine learning modelling is about, trying many different combinations of models and seeing which performs best.\n",
        "\n",
        "Each model you build is a small experiment.\n",
        "\n",
        " Note: One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practitioner's motto: \"experiment, experiment, experiment\".\n",
        "\n",
        "Another thing you'll also find is what you thought may work "
      ],
      "metadata": {
        "id": "vPc-IfyFUWJd"
      },
      "id": "vPc-IfyFUWJd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tracking your experiments**\n",
        "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
        "\n",
        "We've done a simple version of this above (keeping the results in different variables).\n",
        "\n",
        " **Resource:** But as you build more models, you'll want to look into using tools such as:\n",
        "\n",
        "* *TensorBoard* - a component of the TensorFlow library to help track modelling experiments (we'll see this later).\n",
        "\n",
        "* *Weights & Biases* - a tool for tracking all kinds of machine learning experiments (the good news for Weights & Biases is it plugs into TensorBoard)."
      ],
      "metadata": {
        "id": "pD8xaDZ9VBYm"
      },
      "id": "pD8xaDZ9VBYm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##saving our models\n",
        "Saving a model\n",
        "\n",
        "Once you've trained a model and found one which performs to your liking, you'll probably want to save it for use elsewhere (like a web application or mobile device).\n",
        "\n",
        "\n",
        "You can save a TensorFlow/Keras model using model.save().\n",
        "\n",
        "There are two ways to save a model in TensorFlow:\n",
        "\n",
        "1. The SavedModel format (default).\n",
        "\n",
        "2. The HDF5 format.\n",
        "\n",
        "The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in.\n",
        "\n",
        "Which one should you use?\n",
        "\n",
        "It depends on your situation but the SavedModel format will suffice most of the time.\n",
        "\n",
        "Both methods use the same method call."
      ],
      "metadata": {
        "id": "Q-Us72vlVFZ9"
      },
      "id": "Q-Us72vlVFZ9"
    },
    {
      "cell_type": "code",
      "source": [
        "#save model using savemodel format\n",
        "model_2.save(\"model2best_model\")"
      ],
      "metadata": {
        "id": "lzDUh8pTkrfH"
      },
      "id": "lzDUh8pTkrfH",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model using HDF5 format\n",
        "model_2.save(\"model2best_modelhdf5.h5\")"
      ],
      "metadata": {
        "id": "BSgXwn45fC1p"
      },
      "id": "BSgXwn45fC1p",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LOADING IN SAVE MODEL"
      ],
      "metadata": {
        "id": "Nttu26SLgByd"
      },
      "id": "Nttu26SLgByd"
    },
    {
      "cell_type": "code",
      "source": [
        "#Load in  savemodel format\n",
        "\n",
        "loaded_savedmodel_format=tf.keras.models.load_model(\"/content/model2best_model\")\n",
        "loaded_savedmodel_format.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znHza_M-gWrM",
        "outputId": "e1545bb1-2bfe-4964-eef9-7cf141f0df43"
      },
      "id": "znHza_M-gWrM",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo_EFWjbguXY",
        "outputId": "df1d34e4-c0c6-4299-a68a-ebd9b8aa9cee"
      },
      "id": "Oo_EFWjbguXY",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare model2 with savedmodel  format save model\n",
        "model_2_preds=model_2.predict(X_test)\n",
        "loaded_savemodel_preds=loaded_savedmodel_format.predict(X_test)\n",
        "model_2_preds == loaded_savemodel_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPqThrTeg2lC",
        "outputId": "e9965868-b640-42fc-e3d0-5088f17b33f5"
      },
      "id": "CPqThrTeg2lC",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loadin h5 model\n",
        "loaded_h5_model=tf.keras.models.load_model(\"/content/model2best_modelhdf5.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w92UWh9_hYcC",
        "outputId": "92d9c0b2-19bf-447b-b978-3cf095ced117"
      },
      "id": "w92UWh9_hYcC",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare model2 with savedmodel  format save model\n",
        "model_2_preds=model_2.predict(X_test)\n",
        "loaded_h5_model_preds=loaded_h5_model.predict(X_test)\n",
        "model_2_preds == loaded_h5_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzoR3mNWiMLL",
        "outputId": "23b34645-9b79-4898-9d99-90b2516dee18"
      },
      "id": "KzoR3mNWiMLL",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DOWNLOAD A MODEL (or any other file ) from google colab\n",
        "Say you wanted to get your model from Google Colab to your local machine, you can do one of the following things:\n",
        "\n",
        "1 Right click on the file in the files pane and click 'download'.\n",
        "\n",
        "2 Use the code below."
      ],
      "metadata": {
        "id": "7LCbP3mSiiYd"
      },
      "id": "7LCbP3mSiiYd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model (or any file) from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"model2best_modelhdf5.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z_iiUbgmn10v",
        "outputId": "940a6c57-86c4-43d7-d6e3-7d8255eac024"
      },
      "id": "z_iiUbgmn10v",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_66b1e139-45ed-4e9d-a353-9c6280299f91\", \"model2best_modelhdf5.h5\", 17872)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####A larger EXAMPLE"
      ],
      "metadata": {
        "id": "pWdreFe8oBp9"
      },
      "id": "pWdreFe8oBp9"
    },
    {
      "cell_type": "code",
      "source": [
        " #import required  libraries\n",
        " import tensorflow as tf\n",
        " import pandas as pd\n",
        " import matplotlib.pyplot as plt\n",
        " "
      ],
      "metadata": {
        "id": "65XnDAZro7QA"
      },
      "id": "65XnDAZro7QA",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in the insurance dataset\n",
        "insurance =pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ay7wy6BdcVYV",
        "outputId": "9c6aa065-6134-46bd-d6be-dddaf08311b1"
      },
      "id": "ay7wy6BdcVYV",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07f0b1dd-de50-4fe5-9882-db8559efd680\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07f0b1dd-de50-4fe5-9882-db8559efd680')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07f0b1dd-de50-4fe5-9882-db8559efd680 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07f0b1dd-de50-4fe5-9882-db8559efd680');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance[\"sex\"],insurance['age']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvi1dlwUdstl",
        "outputId": "4342418f-8c3a-4890-fddf-a29a5e082189"
      },
      "id": "pvi1dlwUdstl",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0       female\n",
              " 1         male\n",
              " 2         male\n",
              " 3         male\n",
              " 4         male\n",
              "          ...  \n",
              " 1333      male\n",
              " 1334    female\n",
              " 1335    female\n",
              " 1336    female\n",
              " 1337    female\n",
              " Name: sex, Length: 1338, dtype: object, 0       19\n",
              " 1       18\n",
              " 2       28\n",
              " 3       33\n",
              " 4       32\n",
              "         ..\n",
              " 1333    50\n",
              " 1334    18\n",
              " 1335    18\n",
              " 1336    21\n",
              " 1337    61\n",
              " Name: age, Length: 1338, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets try one hot encodigng using get_dummies functuion all to numbers\n",
        "insurance_one_hot=pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "lViOHL6ueGfe",
        "outputId": "d0f4e2f8-a814-4d2c-8f20-a9b0f9adc44e"
      },
      "id": "lViOHL6ueGfe",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0   19  27.900         0  16884.92400           1         0          0   \n",
              "1   18  33.770         1   1725.55230           0         1          1   \n",
              "2   28  33.000         3   4449.46200           0         1          1   \n",
              "3   33  22.705         0  21984.47061           0         1          1   \n",
              "4   32  28.880         0   3866.85520           0         1          1   \n",
              "\n",
              "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0           1                 0                 0                 0   \n",
              "1           0                 0                 0                 1   \n",
              "2           0                 0                 0                 1   \n",
              "3           0                 0                 1                 0   \n",
              "4           0                 0                 1                 0   \n",
              "\n",
              "   region_southwest  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6abb4b46-b8bf-43a0-803b-bfa9c2b0d92a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6abb4b46-b8bf-43a0-803b-bfa9c2b0d92a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6abb4b46-b8bf-43a0-803b-bfa9c2b0d92a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6abb4b46-b8bf-43a0-803b-bfa9c2b0d92a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #create X and y values(featues and labels)\n",
        " X = insurance_one_hot.drop(\"charges\",axis=1)\n",
        " y=  insurance_one_hot[\"charges\"]\n",
        "\n",
        "\n",
        "\n",
        "#view X, y\n",
        "X.head(),y.head()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJRmdUC1exOs",
        "outputId": "9c236bff-b984-4f66-c43c-14c252320083"
      },
      "id": "kJRmdUC1exOs",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              " 0   19  27.900         0           1         0          0           1   \n",
              " 1   18  33.770         1           0         1          1           0   \n",
              " 2   28  33.000         3           0         1          1           0   \n",
              " 3   33  22.705         0           0         1          1           0   \n",
              " 4   32  28.880         0           0         1          1           0   \n",
              " \n",
              "    region_northeast  region_northwest  region_southeast  region_southwest  \n",
              " 0                 0                 0                 0                 1  \n",
              " 1                 0                 0                 1                 0  \n",
              " 2                 0                 0                 1                 0  \n",
              " 3                 0                 1                 0                 0  \n",
              " 4                 0                 1                 0                 0  ,\n",
              " 0    16884.92400\n",
              " 1     1725.55230\n",
              " 2     4449.46200\n",
              " 3    21984.47061\n",
              " 4     3866.85520\n",
              " Name: charges, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42) # set random state for reproducible splits\n",
        "\n",
        "\n",
        "len(X), len(X_train),len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYBRt6QVgyWf",
        "outputId": "88acb015-5473-45e6-ae4b-2185c83638b0"
      },
      "id": "RYBRt6QVgyWf",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build  a neural netwok (sort of like model_2 above)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model\n",
        "insurance_model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2.  Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SDG(),\n",
        "                        metrics=[\"mae\"])\n",
        "#3. Fit the model\n",
        "insurance_model.fit(X_train,y_train,epochs=100)"
      ],
      "metadata": {
        "id": "_g0sejeziGWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f65781c-3988-4db1-ff05-25cc812440fd"
      },
      "id": "_g0sejeziGWl",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 3s 9ms/step - loss: 13342.9727 - mae: 13342.9727\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 13329.9717 - mae: 13329.9717\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13315.9346 - mae: 13315.9346\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 13300.0146 - mae: 13300.0146\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13281.5713 - mae: 13281.5713\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13260.0322 - mae: 13260.0322\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 13235.2822 - mae: 13235.2822\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13207.1514 - mae: 13207.1514\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 13175.4482 - mae: 13175.4482\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13140.1748 - mae: 13140.1748\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13101.1084 - mae: 13101.1084\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 13058.1211 - mae: 13058.1211\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 13011.1934 - mae: 13011.1934\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 12959.9131 - mae: 12959.9131\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 12904.3330 - mae: 12904.3330\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 12843.9795 - mae: 12843.9795\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 12779.0713 - mae: 12779.0713\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 12709.3604 - mae: 12709.3604\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 12634.9258 - mae: 12634.9258\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 12556.0205 - mae: 12556.0205\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 12472.6455 - mae: 12472.6455\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12384.9424 - mae: 12384.9424\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 12292.9873 - mae: 12292.9873\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 12196.6436 - mae: 12196.6436\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 12096.5264 - mae: 12096.5264\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 11992.2236 - mae: 11992.2236\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 11884.4756 - mae: 11884.4756\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 11773.5518 - mae: 11773.5518\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 11659.7119 - mae: 11659.7119\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 11543.2324 - mae: 11543.2324\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 11423.2979 - mae: 11423.2979\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 11300.6543 - mae: 11300.6543\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 11176.1201 - mae: 11176.1201\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 11050.9678 - mae: 11050.9678\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 10924.8887 - mae: 10924.8887\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 10799.0557 - mae: 10799.0557\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 10673.6133 - mae: 10673.6133\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 10548.5283 - mae: 10548.5283\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 10424.7764 - mae: 10424.7764\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 10303.2109 - mae: 10303.2109\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 10182.7451 - mae: 10182.7451\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 10061.2559 - mae: 10061.2559\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 9942.6865 - mae: 9942.6865\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 9825.1777 - mae: 9825.1777\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9710.7246 - mae: 9710.7246\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9595.1396 - mae: 9595.1396\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 9481.5430 - mae: 9481.5430\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 9367.9170 - mae: 9367.9170\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 9256.2031 - mae: 9256.2031\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 9144.1562 - mae: 9144.1562\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 9037.3320 - mae: 9037.3320\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 8934.0244 - mae: 8934.0244\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 8834.7051 - mae: 8834.7051\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8739.5371 - mae: 8739.5371\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8645.7969 - mae: 8645.7969\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8555.3213 - mae: 8555.3213\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 8466.6846 - mae: 8466.6846\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 8382.3799 - mae: 8382.3799\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 8301.2500 - mae: 8301.2500\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8225.6885 - mae: 8225.6885\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8153.3945 - mae: 8153.3945\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 8084.8506 - mae: 8084.8506\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8020.3325 - mae: 8020.3325\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7958.8560 - mae: 7958.8560\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7903.1187 - mae: 7903.1187\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7850.9019 - mae: 7850.9019\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7802.4980 - mae: 7802.4980\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7760.0098 - mae: 7760.0098\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7721.6055 - mae: 7721.6055\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7685.3594 - mae: 7685.3594\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7652.4346 - mae: 7652.4346\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7623.1860 - mae: 7623.1860\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7597.9912 - mae: 7597.9912\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7575.3462 - mae: 7575.3462\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7556.5063 - mae: 7556.5063\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7538.8091 - mae: 7538.8091\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7523.7476 - mae: 7523.7476\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7510.1016 - mae: 7510.1016\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7498.4165 - mae: 7498.4165\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7487.2686 - mae: 7487.2686\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7478.0405 - mae: 7478.0405\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7471.3008 - mae: 7471.3008\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7463.3672 - mae: 7463.3672\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7457.3730 - mae: 7457.3730\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7451.3223 - mae: 7451.3223\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7446.0107 - mae: 7446.0107\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7441.0732 - mae: 7441.0732\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7436.3838 - mae: 7436.3838\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7432.0571 - mae: 7432.0571\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7428.3853 - mae: 7428.3853\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7423.8228 - mae: 7423.8228\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7420.4595 - mae: 7420.4595\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7417.0552 - mae: 7417.0552\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7413.9468 - mae: 7413.9468\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7410.8711 - mae: 7410.8711\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7407.9849 - mae: 7407.9849\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7405.6934 - mae: 7405.6934\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7403.0093 - mae: 7403.0093\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7400.4590 - mae: 7400.4590\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7398.0249 - mae: 7398.0249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bdb77bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QCNTZIn3ZQ0",
        "outputId": "3c2d02d5-be70-44da-809d-18cd5732fcbc"
      },
      "id": "0QCNTZIn3ZQ0",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the results of model on test data\n",
        "\n",
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--tVKaLj31YW",
        "outputId": "3d114e6d-7271-47c6-a172-f2e5945bc946"
      },
      "id": "--tVKaLj31YW",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 5ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.mean(),y_train.median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVkIUEMY7b1V",
        "outputId": "d5ce1914-84a3-4da7-f384-976f6a7a31b3"
      },
      "id": "LVkIUEMY7b1V",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13346.089736364485, 9575.4421)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **OUR MODEL IS NOT PERFORMING WELL< LETS IMPROVE IT**\n",
        "\n",
        "  1. Add an extra layer with more hidden units and use adam optimizer\n",
        "  2. same as above but can train for longer\n",
        "  3. insert our own imagination\n"
      ],
      "metadata": {
        "id": "6w1UKFOl77IM"
      },
      "id": "6w1UKFOl77IM"
    },
    {
      "cell_type": "code",
      "source": [
        "#Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1.Create a model\n",
        "insurance_model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2.compile\n",
        "insurance_model2.compile(loss=tf.keras.losses.mae,\n",
        "                         optimizer=tf.keras.optimizers.Adam(),\n",
        "                         metrics=[\"mae\"])\n",
        "#fit the model\n",
        "insurance_model2.fit(X_train,y_train,epochs=100,verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvQyW_dP8GM6",
        "outputId": "8f59d02e-ba36-4541-a5af-55ad711825f1"
      },
      "id": "KvQyW_dP8GM6",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bca8c550>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "\n",
        "insurance_model2.fit(X_train,y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w3DAEMr96wz",
        "outputId": "a4ebea39-6f26-426d-f0f3-1ae7072e45c9"
      },
      "id": "8w3DAEMr96wz",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4989.4756 - mae: 4989.4756\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4914.9385 - mae: 4914.9385\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4841.3486 - mae: 4841.3486\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4761.7690 - mae: 4761.7690\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4682.7061 - mae: 4682.7061\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4603.9321 - mae: 4603.9321\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4509.5996 - mae: 4509.5996\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4419.8442 - mae: 4419.8442\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4347.3979 - mae: 4347.3979\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4253.3604 - mae: 4253.3604\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4175.2764 - mae: 4175.2764\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4100.2339 - mae: 4100.2339\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4029.2649 - mae: 4029.2649\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3977.6355 - mae: 3977.6355\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3936.2954 - mae: 3936.2954\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3908.2585 - mae: 3908.2585\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3896.7791 - mae: 3896.7791\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3862.3840 - mae: 3862.3840\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3852.5813 - mae: 3852.5813\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3841.7783 - mae: 3841.7783\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.9763 - mae: 3827.9763\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3814.1816 - mae: 3814.1816\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3807.3433 - mae: 3807.3433\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3803.4751 - mae: 3803.4751\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3806.3401 - mae: 3806.3401\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3793.1516 - mae: 3793.1516\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3787.9104 - mae: 3787.9104\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3796.7505 - mae: 3796.7505\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3780.5596 - mae: 3780.5596\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3784.5251 - mae: 3784.5251\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3784.1865 - mae: 3784.1865\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3777.5425 - mae: 3777.5425\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3776.4482 - mae: 3776.4482\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3767.9023 - mae: 3767.9023\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3770.5906 - mae: 3770.5906\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.4436 - mae: 3766.4436\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.5281 - mae: 3762.5281\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.9470 - mae: 3771.9470\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.5349 - mae: 3758.5349\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3777.9016 - mae: 3777.9016\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.5466 - mae: 3763.5466\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3757.8320 - mae: 3757.8320\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3754.5969 - mae: 3754.5969\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.5662 - mae: 3750.5662\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3745.7498 - mae: 3745.7498\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3746.2803 - mae: 3746.2803\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3746.3315 - mae: 3746.3315\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.7607 - mae: 3743.7607\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.6458 - mae: 3750.6458\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3738.6418 - mae: 3738.6418\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3739.3230 - mae: 3739.3230\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.1721 - mae: 3743.1721\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.4570 - mae: 3733.4570\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3740.0420 - mae: 3740.0420\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3730.4871 - mae: 3730.4871\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3728.5632 - mae: 3728.5632\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3726.1628 - mae: 3726.1628\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3730.2346 - mae: 3730.2346\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3736.1382 - mae: 3736.1382\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.4492 - mae: 3726.4492\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3731.3318 - mae: 3731.3318\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3727.8149 - mae: 3727.8149\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3720.4146 - mae: 3720.4146\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3718.5562 - mae: 3718.5562\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3718.3484 - mae: 3718.3484\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3724.4446 - mae: 3724.4446\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3721.0522 - mae: 3721.0522\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3718.0542 - mae: 3718.0542\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3710.9207 - mae: 3710.9207\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3709.1326 - mae: 3709.1326\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3717.2358 - mae: 3717.2358\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3708.6267 - mae: 3708.6267\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3710.4854 - mae: 3710.4854\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3701.2490 - mae: 3701.2490\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3698.9312 - mae: 3698.9312\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3697.9221 - mae: 3697.9221\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3697.8833 - mae: 3697.8833\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3694.8235 - mae: 3694.8235\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3694.8291 - mae: 3694.8291\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.4258 - mae: 3691.4258\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3694.0627 - mae: 3694.0627\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3687.4170 - mae: 3687.4170\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3689.8279 - mae: 3689.8279\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3686.1572 - mae: 3686.1572\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.1565 - mae: 3680.1565\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3681.0054 - mae: 3681.0054\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3684.2095 - mae: 3684.2095\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.8059 - mae: 3680.8059\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3677.2244 - mae: 3677.2244\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3686.4341 - mae: 3686.4341\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3686.9019 - mae: 3686.9019\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3940 - mae: 3676.3940\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3672.4214 - mae: 3672.4214\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3670.8767 - mae: 3670.8767\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3668.1282 - mae: 3668.1282\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3667.2776 - mae: 3667.2776\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3665.4045 - mae: 3665.4045\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3659.3208 - mae: 3659.3208\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3677.0227 - mae: 3677.0227\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3667.1895 - mae: 3667.1895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88c241e210>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate on test\n",
        "insurance_model2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmXYK-P2-Kbf",
        "outputId": "fb5c6b4a-a6a2-4860-9b9d-f0ea7c655227"
      },
      "id": "AmXYK-P2-Kbf",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 6ms/step - loss: 3494.7285 - mae: 3494.7285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3494.728515625, 3494.728515625]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SU8efCI-12M",
        "outputId": "d0e8babf-7042-4ce3-b68e-c17d0dcabb20"
      },
      "id": "4SU8efCI-12M",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 5ms/step - loss: 7539.9517 - mae: 7539.9517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7539.95166015625, 7539.95166015625]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE JUST HALVED  the error rate above\n",
        "\n",
        "LEts create model 3"
      ],
      "metadata": {
        "id": "dpGrPEQI_r0R"
      },
      "id": "dpGrPEQI_r0R"
    },
    {
      "cell_type": "code",
      "source": [
        "#Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1.Create a model\n",
        "insurance_model3=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2.compile\n",
        "insurance_model3.compile(loss=tf.keras.losses.mae,\n",
        "                         optimizer=tf.keras.optimizers.Adam(),\n",
        "                         metrics=[\"mae\"])\n",
        "#fit the model\n",
        "history=insurance_model3.fit(X_train,y_train,epochs=200,verbose=0)"
      ],
      "metadata": {
        "id": "Bp-0n5v9_1sN"
      },
      "id": "Bp-0n5v9_1sN",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model3.fit(X_train,y_train,epochs=200,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA2GDD2rAKIR",
        "outputId": "c0f3eb69-9ac8-4f7a-d5de-405eb5fef1b3"
      },
      "id": "VA2GDD2rAKIR",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3482.1660 - mae: 3482.1660\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.7329 - mae: 3476.7329\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.3398 - mae: 3475.3398\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.9688 - mae: 3480.9688\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2229 - mae: 3477.2229\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3485.3784 - mae: 3485.3784\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.2056 - mae: 3488.2056\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.0613 - mae: 3484.0613\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.2673 - mae: 3477.2673\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.1021 - mae: 3487.1021\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.5366 - mae: 3501.5366\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3487.2878 - mae: 3487.2878\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.8735 - mae: 3475.8735\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3490.8838 - mae: 3490.8838\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.5298 - mae: 3481.5298\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.1731 - mae: 3488.1731\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.7307 - mae: 3483.7307\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.7229 - mae: 3477.7229\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3485.4304 - mae: 3485.4304\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.9312 - mae: 3481.9312\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.1135 - mae: 3477.1135\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.7485 - mae: 3478.7485\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4021 - mae: 3476.4021\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.7422 - mae: 3480.7422\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3495.3818 - mae: 3495.3818\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.5823 - mae: 3479.5823\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.4983 - mae: 3479.4983\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.7732 - mae: 3486.7732\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.3994 - mae: 3487.3994\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.7734 - mae: 3488.7734\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.5737 - mae: 3476.5737\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.5408 - mae: 3488.5408\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3489.1738 - mae: 3489.1738\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.2930 - mae: 3476.2930\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3490.4397 - mae: 3490.4397\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3492.7275 - mae: 3492.7275\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.4192 - mae: 3487.4192\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3490.2798 - mae: 3490.2798\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.4553 - mae: 3481.4553\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3497.7009 - mae: 3497.7009\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.8513 - mae: 3486.8513\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.2195 - mae: 3485.2195\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.1511 - mae: 3478.1511\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.1106 - mae: 3477.1106\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.6516 - mae: 3475.6516\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.0757 - mae: 3475.0757\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.7927 - mae: 3482.7927\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.3245 - mae: 3476.3245\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3495.8484 - mae: 3495.8484\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.8711 - mae: 3481.8711\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.3975 - mae: 3472.3975\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.5825 - mae: 3483.5825\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.1331 - mae: 3479.1331\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.9675 - mae: 3475.9675\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.2302 - mae: 3483.2302\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.5400 - mae: 3480.5400\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.4692 - mae: 3480.4692\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.7632 - mae: 3475.7632\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.9668 - mae: 3475.9668\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.3650 - mae: 3488.3650\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.9043 - mae: 3488.9043\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.3147 - mae: 3485.3147\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.8340 - mae: 3475.8340\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.7461 - mae: 3482.7461\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.1929 - mae: 3474.1929\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.6985 - mae: 3484.6985\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.1094 - mae: 3484.1094\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3484.6765 - mae: 3484.6765\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.5317 - mae: 3474.5317\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.2913 - mae: 3477.2913\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.0884 - mae: 3478.0884\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.4094 - mae: 3476.4094\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3491.7761 - mae: 3491.7761\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.8245 - mae: 3485.8245\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.1079 - mae: 3475.1079\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3474 - mae: 3476.3474\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9846 - mae: 3475.9846\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.1243 - mae: 3477.1243\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.5376 - mae: 3485.5376\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.2310 - mae: 3480.2310\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.9167 - mae: 3478.9167\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3477.6611 - mae: 3477.6611\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.9829 - mae: 3483.9829\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.5730 - mae: 3487.5730\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.6746 - mae: 3476.6746\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.1091 - mae: 3477.1091\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3484.9646 - mae: 3484.9646\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.2319 - mae: 3479.2319\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.2317 - mae: 3482.2317\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.3037 - mae: 3475.3037\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.6667 - mae: 3478.6667\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.1211 - mae: 3479.1211\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.2798 - mae: 3479.2798\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.9031 - mae: 3478.9031\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.9856 - mae: 3474.9856\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.3059 - mae: 3479.3059\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.8145 - mae: 3481.8145\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8362 - mae: 3472.8362\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3501.4797 - mae: 3501.4797\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3499.8403 - mae: 3499.8403\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.6016 - mae: 3479.6016\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3488.5330 - mae: 3488.5330\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3493.6201 - mae: 3493.6201\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3474.3823 - mae: 3474.3823\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3482.0898 - mae: 3482.0898\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3479.6770 - mae: 3479.6770\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3475.3313 - mae: 3475.3313\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3477.4204 - mae: 3477.4204\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.3186 - mae: 3476.3186\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.9688 - mae: 3475.9688\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.3591 - mae: 3481.3591\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3484.4048 - mae: 3484.4048\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3492.0244 - mae: 3492.0244\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3487.2231 - mae: 3487.2231\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3486.8279 - mae: 3486.8279\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.7925 - mae: 3480.7925\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.4922 - mae: 3486.4922\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3478.6494 - mae: 3478.6494\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3476.3997 - mae: 3476.3997\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3482.9473 - mae: 3482.9473\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3486.5129 - mae: 3486.5129\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3490.5415 - mae: 3490.5415\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.5823 - mae: 3487.5823\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.3042 - mae: 3476.3042\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.5940 - mae: 3486.5940\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.3066 - mae: 3486.3066\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.3540 - mae: 3483.3540\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.8342 - mae: 3483.8342\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.7141 - mae: 3487.7141\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.4211 - mae: 3488.4211\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.1917 - mae: 3478.1917\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.3145 - mae: 3480.3145\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.1990 - mae: 3478.1990\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.5686 - mae: 3478.5686\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.9370 - mae: 3477.9370\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.4863 - mae: 3474.4863\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.1899 - mae: 3477.1899\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.5320 - mae: 3481.5320\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.7739 - mae: 3478.7739\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3481.4080 - mae: 3481.4080\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3490.0706 - mae: 3490.0706\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3492.1980 - mae: 3492.1980\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.3242 - mae: 3476.3242\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.0098 - mae: 3479.0098\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3482.8381 - mae: 3482.8381\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.3328 - mae: 3486.3328\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3503.1980 - mae: 3503.1980\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.3032 - mae: 3486.3032\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3481.5747 - mae: 3481.5747\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.6477 - mae: 3483.6477\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3485.6973 - mae: 3485.6973\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3478.9019 - mae: 3478.9019\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.1860 - mae: 3488.1860\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.6304 - mae: 3477.6304\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3487.2310 - mae: 3487.2310\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.5605 - mae: 3480.5605\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3495.4829 - mae: 3495.4829\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3489.0735 - mae: 3489.0735\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.5818 - mae: 3473.5818\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3486.9141 - mae: 3486.9141\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.3228 - mae: 3488.3228\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3478.6394 - mae: 3478.6394\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.9148 - mae: 3474.9148\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.6113 - mae: 3483.6113\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9456 - mae: 3474.9456\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.9395 - mae: 3477.9395\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.0864 - mae: 3481.0864\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.3782 - mae: 3476.3782\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.3220 - mae: 3479.3220\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.2461 - mae: 3474.2461\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.6538 - mae: 3484.6538\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.7283 - mae: 3480.7283\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.9958 - mae: 3481.9958\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3479.2402 - mae: 3479.2402\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.9832 - mae: 3475.9832\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3505.1868 - mae: 3505.1868\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3492.4924 - mae: 3492.4924\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3469.6326 - mae: 3469.6326\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3503.0002 - mae: 3503.0002\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.7283 - mae: 3496.7283\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.8662 - mae: 3484.8662\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3480.5652 - mae: 3480.5652\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3482.5789 - mae: 3482.5789\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3494.7112 - mae: 3494.7112\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3485.2634 - mae: 3485.2634\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.0549 - mae: 3488.0549\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3484.3613 - mae: 3484.3613\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3483.9062 - mae: 3483.9062\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3477.5698 - mae: 3477.5698\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3486.1289 - mae: 3486.1289\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3491.1418 - mae: 3491.1418\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3480.5474 - mae: 3480.5474\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3480.4114 - mae: 3480.4114\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3490.4397 - mae: 3490.4397\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3476.1331 - mae: 3476.1331\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3488.1038 - mae: 3488.1038\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.3389 - mae: 3474.3389\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3485.5605 - mae: 3485.5605\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3475.5208 - mae: 3475.5208\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.9683 - mae: 3474.9683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   #evaluate on test\n",
        "insurance_model3.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99hMl2xmASHH",
        "outputId": "ea0d2064-485d-4052-bc4e-7491da34dc58"
      },
      "id": "99hMl2xmASHH",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3158.8086 - mae: 3158.8086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3158.80859375, 3158.80859375]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate on train set\n",
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA0R6eXXAejJ",
        "outputId": "172ec19d-5e87-4d31-a51e-a75050f1bb56"
      },
      "id": "dA0R6eXXAejJ",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7539.9517 - mae: 7539.9517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7539.95166015625, 7539.95166015625]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #plot history\n",
        "\n",
        " pd.DataFrame(history.history).plot()\n",
        " plt.xlabel(\"epochs\")\n",
        " plt.ylabel(\"loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "7-LvRXepA-dl",
        "outputId": "a0f9994a-4fc5-4084-ec83-65d62048b117"
      },
      "id": "7-LvRXepA-dl",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this, it looks like our model's loss (and MAE) were both still decreasing (in our case, MAE and loss are the same, hence the lines in the plot overlap eachother).\n",
        "\n",
        "What this tells us is the loss might go down if we try training it for longer.\n",
        "\n",
        " Question: How long should you train for?\n",
        "\n",
        "It depends on what problem you're working on. Sometimes training won't take very long, other times it'll take longer than you expect. A common method is to set your model training for a very long time (e.g. 1000's of epochs) but set it up with an **EarlyStopping callback** so it stops automatically when it stops improving. We'll see this in another module.\n",
        "\n",
        "Let's train the same model as above for a little longer. We can do this but calling fit on it again.\n",
        "\n"
      ],
      "metadata": {
        "id": "1kWTdI_JBVwK"
      },
      "id": "1kWTdI_JBVwK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Try training for a little longer (100 more epochs)\n",
        "history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "0z3U1MRvCD0W"
      },
      "id": "0z3U1MRvCD0W",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model trained for 200 total epochs\n",
        "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, y_test)\n",
        "insurance_model_2_loss, insurance_model_2_mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNp9Xg1VCIeK",
        "outputId": "c8845c9b-cf73-4375-a776-0212ea446bf9"
      },
      "id": "qNp9Xg1VCIeK",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 3ms/step - loss: 3494.7285 - mae: 3494.7285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3494.728515625, 3494.728515625)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the model trained for 200 total epochs loss curves\n",
        "pd.DataFrame(history_2.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\"); # note: epochs will only show 100 since we overrid the history variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "I2a43NjxCRH_",
        "outputId": "733e637a-de59-4dd3-c459-e40b3e868f3e"
      },
      "id": "I2a43NjxCRH_",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Preprocessing data (normalization and standardization)**\n",
        "A common practice when working with neural networks is to make sure all of the data you pass to them is in the range 0 to 1.\n",
        "\n",
        "This practice is called *normalization* (scaling all values from their original range to, e.g. between 0 and 100,000 to be between 0 and 1).\n",
        "\n",
        "There is another process call *standardization* which converts all of your data to unit variance and 0 mean.\n",
        "\n",
        "These two practices are often part of a preprocessing pipeline (a series of functions to prepare your data for use with neural networks).\n",
        "\n",
        "Knowing this, some of the major steps you'll take to preprocess your data for a neural network include:\n",
        "\n",
        "Turning all of your data to numbers (a neural network can't handle strings).\n",
        "Making sure your data is in the right shape (verifying input and output shapes).\n",
        "Feature scaling:\n",
        "* **Normalizing** data (making sure all values are between 0 and 1). This is done by subtracting the minimum value then dividing by the maximum value minus the minmum. This is also referred to as min-max scaling.\n",
        "* **Standardization** (making sure all values have a mean of 0 and a variance of 1). This is done by substracting the mean value from the target feature and then dividing it by the standard deviation.\n",
        "* Which one should you use?\n",
        "   * With neural networks you'll tend to favour normalization as they tend to prefer values between 0 and 1 (you'll see this espcially with image processing), however, you'll often find a neural network can perform pretty well with minimal feature scaling.\n",
        "\n",
        " Resource: For more on preprocessing data, I'd recommend reading the following resources:\n",
        "\n",
        "* Scikit-Learn's documentation on preprocessing data.\n",
        "* Scale, Standardize or Normalize with Scikit-Learn by Jeff Hale.\n",
        "\n",
        "\n",
        "We've already turned our data into numbers using get_dummies(), let's see how we'd normalize it as well."
      ],
      "metadata": {
        "id": "7xRd3yCUE0tY"
      },
      "id": "7xRd3yCUE0tY"
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "HdqElEa-FNJS",
        "outputId": "dd18c9a6-dcc3-4832-9f20-9f8ec753ebec"
      },
      "id": "HdqElEa-FNJS",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0      19  27.900         0           1         0          0           1   \n",
              "1      18  33.770         1           0         1          1           0   \n",
              "2      28  33.000         3           0         1          1           0   \n",
              "3      33  22.705         0           0         1          1           0   \n",
              "4      32  28.880         0           0         1          1           0   \n",
              "...   ...     ...       ...         ...       ...        ...         ...   \n",
              "1333   50  30.970         3           0         1          1           0   \n",
              "1334   18  31.920         0           1         0          1           0   \n",
              "1335   18  36.850         0           1         0          1           0   \n",
              "1336   21  25.800         0           1         0          1           0   \n",
              "1337   61  29.070         0           1         0          0           1   \n",
              "\n",
              "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                    0                 0                 0                 1  \n",
              "1                    0                 0                 1                 0  \n",
              "2                    0                 0                 1                 0  \n",
              "3                    0                 1                 0                 0  \n",
              "4                    0                 1                 0                 0  \n",
              "...                ...               ...               ...               ...  \n",
              "1333                 0                 1                 0                 0  \n",
              "1334                 1                 0                 0                 0  \n",
              "1335                 0                 0                 1                 0  \n",
              "1336                 0                 0                 0                 1  \n",
              "1337                 0                 1                 0                 0  \n",
              "\n",
              "[1338 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-600ae1c4-c925-4d11-b15e-4c8bd0e129be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-600ae1c4-c925-4d11-b15e-4c8bd0e129be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-600ae1c4-c925-4d11-b15e-4c8bd0e129be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-600ae1c4-c925-4d11-b15e-4c8bd0e129be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
      ],
      "metadata": {
        "id": "XIhqt7zLG4-2"
      },
      "id": "XIhqt7zLG4-2",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iOsr-urhHH6O",
        "outputId": "a16458dc-185e-426a-9f39-4756654cdced"
      },
      "id": "iOsr-urhHH6O",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9223428-933f-42b8-9cd7-9386434106e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9223428-933f-42b8-9cd7-9386434106e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9223428-933f-42b8-9cd7-9386434106e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9223428-933f-42b8-9cd7-9386434106e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, just as before, we need to transform the non-numerical columns into numbers and this time we'll also be normalizing the numerical columns with different ranges (to make sure they're all between 0 and 1).\n",
        "\n",
        "To do this, we're going to use a few classes from Scikit-Learn:\n",
        "\n",
        "* make_column_transformer - build a multi-step data preprocessing function for the folllowing transformations:\n",
        " *  MinMaxScaler - make sure all numerical columns are normalized (between 0 and 1).\n",
        " *  OneHotEncoder - one hot encode the non-numerical columns.\n",
        "Let's see them in action."
      ],
      "metadata": {
        "id": "6RXhtAR0HLCZ"
      },
      "id": "6RXhtAR0HLCZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "tgeAK03YHYam"
      },
      "id": "tgeAK03YHYam",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-normalized and non-one-hot encoded data example\n",
        "X_train.loc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y8HI-PjIY0i",
        "outputId": "680fc31e-8e6c-4522-c265-429cb640ed1f"
      },
      "id": "6y8HI-PjIY0i",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized and one-hot encoded example\n",
        "X_train_normal[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMsFYldPIhsk",
        "outputId": "7ce80860-0f4b-49b2-e1fd-a59b02414474"
      },
      "id": "aMsFYldPIhsk",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
        "X_train_normal.shape, X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjoXNEVtIpfx",
        "outputId": "4381beb5-2628-4cd9-babc-7b8588807eb2"
      },
      "id": "cjoXNEVtIpfx",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (1070, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is normalized and numerical, let's model it.\n",
        "\n",
        "We'll use the same model as insurance_model_2."
      ],
      "metadata": {
        "id": "KilHJmB3I-bN"
      },
      "id": "KilHJmB3I-bN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model for 200 epochs (same as insurance_model_2)\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=200, verbose=0) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd21LcbGIzQs",
        "outputId": "98367f08-17f7-40be-8bbe-a75b00c1984f"
      },
      "id": "Pd21LcbGIzQs",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bd2f4a90>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwv_UNTGJSaF",
        "outputId": "6257f3ab-d26f-40f2-eced-0c038b544509"
      },
      "id": "qwv_UNTGJSaF",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.6980 - mae: 3472.6980\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.8572 - mae: 3471.8572\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.2742 - mae: 3472.2742\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.3691 - mae: 3472.3691\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3475.1533 - mae: 3475.1533\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.2314 - mae: 3473.2314\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.7371 - mae: 3471.7371\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.9429 - mae: 3472.9429\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1843 - mae: 3472.1843\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3472.8232 - mae: 3472.8232\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.8567 - mae: 3472.8567\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.7183 - mae: 3471.7183\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.6152 - mae: 3473.6152\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.3777 - mae: 3475.3777\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.8613 - mae: 3472.8613\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.4529 - mae: 3472.4529\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.6379 - mae: 3471.6379\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8042 - mae: 3472.8042\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.5627 - mae: 3472.5627\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.3467 - mae: 3472.3467\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.5579 - mae: 3471.5579\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3475.5071 - mae: 3475.5071\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.9890 - mae: 3474.9890\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.6069 - mae: 3471.6069\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.4065 - mae: 3473.4065\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.8064 - mae: 3473.8064\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.8169 - mae: 3471.8169\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.2317 - mae: 3472.2317\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.1003 - mae: 3472.1003\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.6111 - mae: 3474.6111\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.5029 - mae: 3473.5029\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.0269 - mae: 3472.0269\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8274 - mae: 3474.8274\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.4031 - mae: 3471.4031\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.7029 - mae: 3471.7029\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.3821 - mae: 3472.3821\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.3425 - mae: 3472.3425\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8145 - mae: 3472.8145\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.7522 - mae: 3471.7522\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.8713 - mae: 3473.8713\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.3284 - mae: 3473.3284\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.7092 - mae: 3477.7092\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8562 - mae: 3472.8562\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.1272 - mae: 3472.1272\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.0486 - mae: 3471.0486\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3474.5269 - mae: 3474.5269\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.1636 - mae: 3474.1636\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.5137 - mae: 3472.5137\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.3438 - mae: 3474.3438\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.2637 - mae: 3472.2637\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.0864 - mae: 3474.0864\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.9463 - mae: 3473.9463\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.7039 - mae: 3472.7039\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3476.9019 - mae: 3476.9019\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.9146 - mae: 3474.9146\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.6960 - mae: 3471.6960\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.1812 - mae: 3472.1812\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.4951 - mae: 3471.4951\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.3306 - mae: 3473.3306\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.2214 - mae: 3472.2214\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.9333 - mae: 3472.9333\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.0676 - mae: 3471.0676\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3471.9817 - mae: 3471.9817\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.8916 - mae: 3473.8916\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.7070 - mae: 3473.7070\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.0916 - mae: 3473.0916\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3473.0552 - mae: 3473.0552\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.3396 - mae: 3474.3396\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.7998 - mae: 3471.7998\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.2058 - mae: 3474.2058\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.1477 - mae: 3473.1477\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.5962 - mae: 3472.5962\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3473.2288 - mae: 3473.2288\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.9006 - mae: 3471.9006\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3472.0735 - mae: 3472.0735\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.6978 - mae: 3473.6978\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.4756 - mae: 3471.4756\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.9702 - mae: 3471.9702\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.1873 - mae: 3473.1873\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.2629 - mae: 3472.2629\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.5208 - mae: 3472.5208\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.9902 - mae: 3472.9902\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.5513 - mae: 3472.5513\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.0803 - mae: 3472.0803\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.4014 - mae: 3473.4014\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.7090 - mae: 3471.7090\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.0881 - mae: 3472.0881\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.0098 - mae: 3472.0098\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.6501 - mae: 3472.6501\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.6060 - mae: 3472.6060\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.3528 - mae: 3471.3528\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.9592 - mae: 3472.9592\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.3691 - mae: 3471.3691\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.0137 - mae: 3472.0137\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3472.8586 - mae: 3472.8586\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.0847 - mae: 3474.0847\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.8369 - mae: 3473.8369\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.9175 - mae: 3471.9175\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.5083 - mae: 3473.5083\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8867 - mae: 3472.8867\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.7925 - mae: 3473.7925\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.0789 - mae: 3472.0789\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.2935 - mae: 3472.2935\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.3418 - mae: 3472.3418\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8203 - mae: 3472.8203\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.8047 - mae: 3471.8047\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.0913 - mae: 3475.0913\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.7505 - mae: 3472.7505\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.2908 - mae: 3475.2908\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.4136 - mae: 3474.4136\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.8511 - mae: 3474.8511\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.0308 - mae: 3473.0308\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8438 - mae: 3472.8438\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.8564 - mae: 3474.8564\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.5183 - mae: 3472.5183\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3475.0291 - mae: 3475.0291\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.6536 - mae: 3472.6536\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1738 - mae: 3472.1738\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3474.3145 - mae: 3474.3145\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.0518 - mae: 3473.0518\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.4866 - mae: 3471.4866\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.6611 - mae: 3472.6611\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.3687 - mae: 3472.3687\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3472.0144 - mae: 3472.0144\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.3752 - mae: 3472.3752\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.4680 - mae: 3472.4680\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3474.3435 - mae: 3474.3435\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.5833 - mae: 3473.5833\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3473.5300 - mae: 3473.5300\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.8896 - mae: 3472.8896\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.4321 - mae: 3472.4321\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1338 - mae: 3472.1338\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.0190 - mae: 3472.0190\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1904 - mae: 3472.1904\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.9321 - mae: 3471.9321\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.8445 - mae: 3471.8445\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.7468 - mae: 3472.7468\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1711 - mae: 3472.1711\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3473.2363 - mae: 3473.2363\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.3416 - mae: 3472.3416\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3474.1445 - mae: 3474.1445\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.5820 - mae: 3473.5820\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.6687 - mae: 3473.6687\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.9888 - mae: 3473.9888\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3472.8394 - mae: 3472.8394\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3474.5537 - mae: 3474.5537\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3472.2454 - mae: 3472.2454\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.6331 - mae: 3473.6331\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3471.6235 - mae: 3471.6235\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.0559 - mae: 3473.0559\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.2800 - mae: 3473.2800\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.3052 - mae: 3473.3052\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3471.8018 - mae: 3471.8018\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3473.6343 - mae: 3473.6343\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.1077 - mae: 3473.1077\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.7917 - mae: 3473.7917\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.4509 - mae: 3473.4509\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3471.8896 - mae: 3471.8896\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3471.7188 - mae: 3471.7188\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.0854 - mae: 3473.0854\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3471.4868 - mae: 3471.4868\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.2275 - mae: 3472.2275\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.1841 - mae: 3473.1841\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3473.6912 - mae: 3473.6912\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3472.2979 - mae: 3472.2979\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.1338 - mae: 3472.1338\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.8386 - mae: 3472.8386\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3472.4163 - mae: 3472.4163\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3471.4392 - mae: 3471.4392\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.0771 - mae: 3472.0771\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.9253 - mae: 3471.9253\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.4893 - mae: 3472.4893\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.9141 - mae: 3472.9141\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.8755 - mae: 3472.8755\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.8584 - mae: 3471.8584\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.4133 - mae: 3473.4133\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.1604 - mae: 3474.1604\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.8694 - mae: 3472.8694\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3477.0017 - mae: 3477.0017\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.7566 - mae: 3472.7566\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.7751 - mae: 3472.7751\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.0613 - mae: 3473.0613\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.1155 - mae: 3472.1155\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.1653 - mae: 3473.1653\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.9531 - mae: 3472.9531\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.4797 - mae: 3472.4797\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.1055 - mae: 3473.1055\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.1191 - mae: 3471.1191\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3471.6765 - mae: 3471.6765\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.3345 - mae: 3473.3345\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3479.7361 - mae: 3479.7361\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.2913 - mae: 3472.2913\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3473.5842 - mae: 3473.5842\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3472.3618 - mae: 3472.3618\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3471.5166 - mae: 3471.5166\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3474.9438 - mae: 3474.9438\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.9214 - mae: 3473.9214\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3473.2036 - mae: 3473.2036\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3472.6113 - mae: 3472.6113\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3475.6699 - mae: 3475.6699\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88bcf1b990>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model_4.evaluate(X_test_normal,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXXTUbltJnDP",
        "outputId": "a96ed7a8-6abe-4173-f862-03957cf9ac41"
      },
      "id": "wXXTUbltJnDP",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 3163.1641 - mae: 3163.1641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3163.1640625, 3163.1640625]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FROM OUR MODEL 2\n",
        "\n",
        "#9/9 [==============================] - 0s 6ms/step - loss: 3494.7285 - mae: 3494.7285\n",
        "#[3494.728515625, 3494.728515625]\n",
        "\n",
        "#FROM OUR MODEL 3\n",
        "\n",
        "\n",
        "#9/9 [==============================] - 0s 3ms/step - loss: 3158.8086 - mae: 3158.8086\n",
        "#[3158.80859375, 3158.80859375]"
      ],
      "metadata": {
        "id": "Tsyn8pgGKO4x"
      },
      "id": "Tsyn8pgGKO4x",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJp6ytzhK1mQ"
      },
      "id": "jJp6ytzhK1mQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b673cb82",
        "a5167f8b",
        "af9dfa11"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}